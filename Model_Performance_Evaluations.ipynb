{ 
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model Performance Evaluations.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPTFilqzlPnHcAgD9vK5dL5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qwerlarlgus/CNN-Cats-Dogs/blob/main/Model_Performance_Evaluations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2duCzJYXA0_"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4fYGMMGXEdq"
      },
      "source": [
        "import glob\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img\r\n",
        "from tensorflow.keras.models import load_model\r\n",
        "import model_evaluation_utils as meu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aTp7FQ_XCot"
      },
      "source": [
        "#basic_cnn = load_model('cats_dogs_basic_cnn.h5')\r\n",
        "basic_cnn = load_model('10-06-me.h5')\r\n",
        "img_aug_cnn = load_model('cats_dogs_cnn_img_aug.h5')\r\n",
        "tl_cnn = load_model('cats_dogs_tlearn_basic_cnn.h5')\r\n",
        "tl_img_aug_cnn = load_model('cats_dogs_tlearn_basic_cnn.h5')\r\n",
        "tl_img_aug_finetune_cnn = load_model('cats_dogs_tlearn_finetune_img_aug.h5')\r\n",
        "tl_img_aug_finetune_cnn = load_model('cats_dogs_tlearn_img_aug_cnn.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eVnlXRMXC7w"
      },
      "source": [
        "from tensorflow.keras.applications import vgg16\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "import tensorflow.keras\r\n",
        "\r\n",
        "IMG_DIM = (150, 150)\r\n",
        "input_shape = (150, 150, 3)\r\n",
        "num2class_label_transformer = lambda l: ['cat' if x == 0 else 'dog' for x in l]\r\n",
        "class2num_label_transformer = lambda l: [0 if x == 'cat' else 1 for x in l]\r\n",
        "\r\n",
        "\r\n",
        "vgg = vgg16.VGG16(include_top=False, weights='imagenet', \r\n",
        "                  input_shape=input_shape)\r\n",
        "output = vgg.layers[-1].output\r\n",
        "output = tensorflow.keras.layers.Flatten()(output)\r\n",
        "vgg_model = Model(vgg.input, output)\r\n",
        "vgg_model.trainable = False\r\n",
        "\r\n",
        "def get_bottleneck_features(model, input_imgs):\r\n",
        "    \r\n",
        "    features = model.predict(input_imgs, verbose=0)\r\n",
        "    return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AztLePnlXDBT"
      },
      "source": [
        "sample_img_path = 'my_cat.jpg'\r\n",
        "sample_img = load_img(sample_img_path, target_size=IMG_DIM)\r\n",
        "sample_img_tensor = img_to_array(sample_img)\r\n",
        "sample_img_tensor = np.expand_dims(sample_img_tensor, axis=0)\r\n",
        "sample_img_tensor /= 255.\r\n",
        "\r\n",
        "print(sample_img_tensor.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvnofviuXDG8"
      },
      "source": [
        "plt.imshow(sample_img_tensor[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRg7ECKSXDMY"
      },
      "source": [
        "cnn_prediction = num2class_label_transformer(basic_cnn.predict_classes(sample_img_tensor, verbose=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAQcW3mUXDRJ"
      },
      "source": [
        "cnn_img_aug_prediction = num2class_label_transformer(img_aug_cnn.predict_classes(sample_img_tensor, verbose=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUHAQaR3XDV5"
      },
      "source": [
        "tlearn_cnn_prediction = num2class_label_transformer(tl_cnn.predict_classes(get_bottleneck_features(vgg_model, \r\n",
        "                                                  sample_img_tensor), verbose=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9JEdbHYXDbP"
      },
      "source": [
        "tlearn_cnn_img_aug_prediction = num2class_label_transformer(tl_img_aug_cnn.predict_classes(sample_img_tensor, verbose=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oECA537HXDf0"
      },
      "source": [
        "tlearn_cnn_finetune_img_aug_prediction = num2class_label_transformer(tl_img_aug_finetune_cnn.predict_classes(sample_img_tensor, \r\n",
        "                                                                                                         verbose=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndPTkce5XDkl"
      },
      "source": [
        "print('Predictions for our sample image:\\n', \r\n",
        "      '\\nBasic CNN:', cnn_prediction, \r\n",
        "      '\\nCNN with Img Augmentation:', cnn_img_aug_prediction, \r\n",
        "      '\\nPre-trained CNN (Transfer Learning):', tlearn_cnn_prediction,\r\n",
        "#      '\\nPre-trained CNN with Img Augmentation (Transfer Learning):', tlearn_cnn_img_aug_prediction, \r\n",
        "      '\\nPre-trained CNN with Fine-tuning & Img Augmentation (Transfer Learning):', tlearn_cnn_finetune_img_aug_prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lj5z9PGpXDpk"
      },
      "source": [
        "tl_img_aug_finetune_cnn.layers[0].layers[1:9]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Oi8azhiXDub"
      },
      "source": [
        "from tensorflow.keras import models\r\n",
        "\r\n",
        "# Extracts the outputs of the top 8 layers:\r\n",
        "layer_outputs = [layer.output for layer in tl_img_aug_finetune_cnn.layers[0].layers[1:9]]\r\n",
        "# Creates a model that will return these outputs, given the model input:\r\n",
        "activation_model = models.Model(inputs=tl_img_aug_finetune_cnn.layers[0].layers[1].input, outputs=layer_outputs)\r\n",
        "# This will return a list of 8 Numpy array\r\n",
        "# one array per layer activation\r\n",
        "activations = activation_model.predict(sample_img_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7Lwvpi-XXVU"
      },
      "source": [
        "print ('Sample layer shape:', activations[0].shape)\r\n",
        "print('Sample convolution (activation map) shape:', activations[0][0, :, :, 1].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zdt6-NhgXXb_"
      },
      "source": [
        "fig, ax = plt.subplots(1,5, figsize=(16, 6))\r\n",
        "ax[0].imshow(activations[0][0, :, :, 10], cmap='bone')\r\n",
        "ax[1].imshow(activations[0][0, :, :, 25], cmap='bone')\r\n",
        "ax[2].imshow(activations[0][0, :, :, 40], cmap='bone')\r\n",
        "ax[3].imshow(activations[0][0, :, :, 55], cmap='bone')\r\n",
        "ax[4].imshow(activations[0][0, :, :, 63], cmap='bone')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFRVFZiCXXh9"
      },
      "source": [
        "import tensorflow.keras\r\n",
        "\r\n",
        "# These are the names of the layers, so can have them as part of our plot\r\n",
        "layer_names = []\r\n",
        "for layer in tl_img_aug_finetune_cnn.layers[0].layers[1:9]:\r\n",
        "    layer_names.append(layer.name)\r\n",
        "\r\n",
        "images_per_row = 16\r\n",
        "\r\n",
        "# Now let's display our feature maps\r\n",
        "for layer_name, layer_activation in zip(layer_names, activations):\r\n",
        "    # This is the number of features in the feature map\r\n",
        "    n_features = layer_activation.shape[-1]\r\n",
        "\r\n",
        "    # The feature map has shape (1, size, size, n_features)\r\n",
        "    size = layer_activation.shape[1]\r\n",
        "\r\n",
        "    # We will tile the activation channels in this matrix\r\n",
        "    n_cols = n_features // images_per_row\r\n",
        "    display_grid = np.zeros((size * n_cols, images_per_row * size))\r\n",
        "\r\n",
        "    # We'll tile each filter into this big horizontal grid\r\n",
        "    for col in range(n_cols):\r\n",
        "        for row in range(images_per_row):\r\n",
        "            channel_image = layer_activation[0,\r\n",
        "                                             :, :,\r\n",
        "                                             col * images_per_row + row]\r\n",
        "            # Post-process the feature to make it visually palatable\r\n",
        "            channel_image -= channel_image.mean()\r\n",
        "            channel_image /= channel_image.std()\r\n",
        "            channel_image *= 64\r\n",
        "            channel_image += 128\r\n",
        "            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\r\n",
        "            display_grid[col * size : (col + 1) * size,\r\n",
        "                         row * size : (row + 1) * size] = channel_image\r\n",
        "\r\n",
        "    # Display the grid\r\n",
        "    scale = 1. / size\r\n",
        "    plt.figure(figsize=(scale * display_grid.shape[1],\r\n",
        "                        scale * display_grid.shape[0]))\r\n",
        "    plt.title(layer_name)\r\n",
        "    plt.grid(False)\r\n",
        "    plt.imshow(display_grid, aspect='auto', cmap='bone')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwN4mA5nXXnn"
      },
      "source": [
        "IMG_DIM = (150, 150)\r\n",
        "\r\n",
        "test_files = glob.glob('test_data\\\\*')\r\n",
        "test_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in test_files]\r\n",
        "test_imgs = np.array(test_imgs)\r\n",
        "test_labels = [fn.split('\\\\')[1].split('.')[0].strip() for fn in test_files]\r\n",
        "\r\n",
        "print('Test dataset shape:', test_imgs.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clQ4xECrXgNs"
      },
      "source": [
        "test_imgs_scaled = test_imgs.astype('float32')\r\n",
        "test_imgs_scaled /= 255\r\n",
        "\r\n",
        "test_labels_enc = class2num_label_transformer(test_labels)\r\n",
        "\r\n",
        "print(test_labels[0:5], test_labels_enc[0:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjmYSnOTXiT3"
      },
      "source": [
        "print(list(set(test_labels)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5GkVc0zXieR"
      },
      "source": [
        "predictions = basic_cnn.predict_classes(test_imgs_scaled, verbose=0)\r\n",
        "predictions = num2class_label_transformer(predictions)\r\n",
        "\r\n",
        "#meu.display_model_performance_metrics(true_labels=test_labels, predicted_labels=predictions, \r\n",
        "#                                      classes=list(set(test_labels)))\r\n",
        "meu.display_model_performance_metrics(true_labels=test_labels, predicted_labels=predictions, \\\r\n",
        "                                     classes=['dog','cat'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zoDA7yEXilB"
      },
      "source": [
        "predictions = img_aug_cnn.predict_classes(test_imgs_scaled, verbose=0)\r\n",
        "predictions = num2class_label_transformer(predictions)\r\n",
        "\r\n",
        "meu.display_model_performance_metrics(true_labels=test_labels, predicted_labels=predictions, \r\n",
        "                                      classes=list(set(test_labels)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yu_YtA7EXirB"
      },
      "source": [
        "test_bottleneck_features = get_bottleneck_features(vgg_model, test_imgs_scaled)\r\n",
        "\r\n",
        "predictions = tl_cnn.predict_classes(test_bottleneck_features, verbose=0)\r\n",
        "predictions = num2class_label_transformer(predictions)\r\n",
        "\r\n",
        "meu.display_model_performance_metrics(true_labels=test_labels, predicted_labels=predictions, \r\n",
        "                                      classes=list(set(test_labels)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dv_Tu9U9XmYj"
      },
      "source": [
        "predictions = tl_img_aug_cnn.predict_classes(test_imgs_scaled, verbose=0)\r\n",
        "predictions = num2class_label_transformer(predictions)\r\n",
        "\r\n",
        "meu.display_model_performance_metrics(true_labels=test_labels, predicted_labels=predictions, classes=list(set(test_labels)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bjg7XMz9Xmgx"
      },
      "source": [
        "meu.plot_model_roc_curve(basic_cnn, test_imgs_scaled, \r\n",
        "                                  true_labels=test_labels_enc, class_names=[0, 1])\r\n",
        "\r\n",
        "meu.plot_model_roc_curve(tl_img_aug_finetune_cnn, test_imgs_scaled, \r\n",
        "                                  true_labels=test_labels_enc, class_names=[0, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q66EViNVXmn8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsIeCRYAXmw7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
